{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOYCLLYVhukEdbr4bKOqvvL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shamwq/otbtf_tutorials_resources/blob/master/Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovGbKp5NzYpK"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created in 2017\n",
        "\n",
        "@author: mass.gargiulo & anto.mazza\n",
        "\"\"\"\n",
        "\n",
        "#############\n",
        "#   A CNN-Based Fusion Method for Feature Extraction from Sentinel Data\n",
        "\n",
        "#(http://www.mdpi.com/2072-4292/10/2/236) \n",
        "#############\n",
        "from __future__ import print_function\n",
        "\n",
        "from funct_Test import *\n",
        "import numpy as np\n",
        "import theano\n",
        "import theano.tensor as T\n",
        "import lasagne\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "\n",
        "def main(data_folder, model_folder, output_folder, identifier):\n",
        "\n",
        "        # Load the dataset\n",
        "\n",
        "    print(\"Loading data...\")\n",
        "    num = 1\n",
        "    x = load_input(data_folder,identifier,num)\n",
        "    \n",
        "    # Prepare Theano variables for inputs and targets\n",
        "    input_var = T.tensor4('inputs')\n",
        "    prediction = T.tensor4('targets') \n",
        "    \n",
        "    # Model building\n",
        "    print(\"Building model and compiling functions...\")\n",
        "    network = build_cnn(input_var,x.shape[1])\n",
        "#    identifier = identifier +'_date_'+str(num)\n",
        "    with np.load(model_folder+'model_ID'+ identifier +'.npz') as g:\n",
        "        param_values = [g['arr_%d' % i] for i in range(len(g.files))]\n",
        "    lasagne.layers.set_all_param_values(network, param_values)\n",
        "\n",
        "     \n",
        "    prediction = lasagne.layers.get_output(network, deterministic=True)\n",
        "    \n",
        "    \n",
        "    # Compile a function performing a training step on a mini-batch (by giving\n",
        "    # the updates dictionary) and returning the corresponding training loss:\n",
        "    test_fn = theano.function([input_var], prediction)#, allow_input_downcast=True)#,n0]\n",
        "    pred_err = test_fn(x)\n",
        "    ndvi1 = pred_err[0,0,:,:]\n",
        "    \n",
        "    \n",
        "    \n",
        "    im = output_folder + identifier + '_NDVI_PRED.tif'\n",
        "    ndvi1_array = np.asarray(ndvi1)\n",
        "    ndvi1_array = Image.fromarray(ndvi1_array, mode='F')\n",
        "    ndvi1_array.save(im, \"TIFF\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    kwargs = {}\n",
        "    kwargs['data_folder'] = './DATASET/'\n",
        "    kwargs['model_folder'] = './MODEL/'\n",
        "    kwargs['output_folder'] = './IMAGES/'\n",
        "    kwargs['identifier'] = 'OPTII'\n",
        "    main(kwargs['data_folder'], kwargs['model_folder'], kwargs['output_folder'], kwargs['identifier'])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}